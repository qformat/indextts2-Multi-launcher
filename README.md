<div align="center">
  <h1>IndexTTS 2-Multi-launcher</h1>
  <p>
    <a href="https://github.com/index-tts/index-tts">
        <img src="https://img.shields.io/badge/GitHub-Code-orange?logo=github"/>
    </a>
    <a href="https://huggingface.co/IndexTeam/IndexTTS-2.0">
        <img src="https://img.shields.io/badge/HuggingFace-Model-blue?logo=huggingface" />
    </a>
    <a href="https://modelscope.cn/models/IndexTeam/IndexTTS-2.0">
        <img src="https://img.shields.io/badge/ModelScope-Model-purple?logo=modelscope"/>
    </a>
  </p>
  <p>
    <strong>English</strong> | <a href="#ä¸­æ–‡è¯´æ˜">ä¸­æ–‡è¯´æ˜</a>
  </p>
</div>

## ğŸ“– Introduction

**IndexTTS 2-Multi-launcher** is a state-of-the-art auto-regressive text-to-speech system that achieves a breakthrough in **emotional expressiveness** and **duration control**.

Unlike traditional TTS models, IndexTTS 2-Multi-launcher allows you to:

- **Control Emotion**: Generate speech with rich, specific emotions (e.g., happy, angry, sad, etc.) using text prompts or reference audio.
- **Control Duration**: Precisely dictate how long the spoken segment should be, enabling perfect synchronization for video dubbing.
- **Zero-Shot Cloning**: Clone a speaker's voice using only a short audio sample (10-15 seconds recommended).

This repository contains the official implementation along with a **built-in graphical user interface (GUI)** for easy inference and batch processing.

## âœ¨ Features

- **ğŸ­ Rich Emotion Support**: Automatically detects emotion from text or allows manual specification via vectors.
- **â±ï¸ Duration Control**: Specify the exact duration for the generated speech.
- **ğŸ™ï¸ Zero-Shot Voice Cloning**: High-fidelity voice cloning with just a single reference audio.
- **ğŸ–¥ï¸ User-Friendly GUI**: A modern, dark-themed UI built with Flet, supporting:
  - Real-time generation log viewing.
  - History management and playback.
  - Batch processing editor.
  - Auto-update capability.
- **ğŸš€ Efficient Inference**: Optimized for NVIDIA GPUs with optional CUDA kernel support for BigVGAN.

## ğŸ› ï¸ Installation

### Prerequisites

- **OS**: Windows 10/11 (Recommended) or Linux.
- **Python**: Version 3.10 is recommended.
- **GPU**: NVIDIA GPU with CUDA 11.8+ (Strongly recommended for performance).

### Steps

1. **Clone the repository**

   ```bash
   git clone https://github.com/qformat/indextts2-Multi-launcher.git
   cd indextts2-Multi-launcher
   ```

2. **Create a virtual environment**

   ```bash
   python -m venv venv
   # Activate:
   # Windows:
   .\venv\Scripts\activate
   # Linux:
   source venv/bin/activate
   ```

3. **Install dependencies**

   ```bash
   # Install PyTorch with CUDA support first (adjust for your CUDA version)
   pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118

   # Install other requirements
   pip install -r requirements.txt
   ```

## ğŸ“¥ Model Download & Setup

IndexTTS 2-Multi-launcher requires several model files to function. Some can be downloaded automatically, but the core models **must be downloaded manually**.

### 1. Core Models (Manual Download Required)

Download these files from [HuggingFace](https://huggingface.co/IndexTeam/IndexTTS-2.0) or [ModelScope](https://modelscope.cn/models/IndexTeam/IndexTTS-2.0) and place them in the `checkpoints/` directory:

| Filename    | Description             | Target Path             |
| :---------- | :---------------------- | :---------------------- |
| `gpt.pth`   | Main AR model weights   | `checkpoints/gpt.pth`   |
| `s2mel.pth` | Diffusion model weights | `checkpoints/s2mel.pth` |
| `feat1.pt`  | Speaker feature matrix  | `checkpoints/feat1.pt`  |
| `feat2.pt`  | Emotion feature matrix  | `checkpoints/feat2.pt`  |

### 2. Auxiliary Models (Auto-Download / Manual)

These models are handled by third-party libraries (Transformers, BigVGAN). The program will attempt to download them automatically if missing. **If you have network issues**, download them manually and place them as follows:

| Model Name       | Source                                | Manual Path (Recommended)                                          |
| :--------------- | :------------------------------------ | :----------------------------------------------------------------- |
| **Qwen Emotion** | `Qwen/Qwen1.5-0.5B-Chat`              | `checkpoints/hub/qwen0.6bemo4-merge` (Extract content here)        |
| **BigVGAN**      | `nvidia/bigvgan_v2_22khz_80band_256x` | `checkpoints/nvidia_bigvgan_v2_22khz_80band_256x`                  |
| **W2V-BERT**     | `facebook/w2v-bert-2.0`               | `checkpoints/hub/models--facebook--w2v-bert-2.0` (HF Cache format) |
| **MaskGCT**      | `amphion/MaskGCT`                     | `checkpoints/amphion_MaskGCT/semantic_codec/model.safetensors`     |

> **Note on Qwen**: The config expects the Qwen emotion model at `checkpoints/hub/qwen0.6bemo4-merge`. Please rename the folder if necessary after downloading.

### ğŸŒ Network Issues? Use a Mirror

If you cannot access Hugging Face, you can use a mirror site. Set the environment variable before running the program:

**PowerShell:**

```powershell
$env:HF_ENDPOINT = "https://hf-mirror.com"
python launcher.py
```

**Bash:**

```bash
export HF_ENDPOINT=https://hf-mirror.com
python src/main.py
```

## ğŸš€ Usage

### Start the GUI

Run the launcher script to start the application:

```bash
python launcher.py
```

### Basic Operation

1. **Select Models**: Ensure the checkpoints are loaded in the settings.
2. **Reference Audio**: Upload a clear speech sample (10-15s) of the voice you want to clone.
3. **Input Text**: Type the text you want to synthesize.
4. **Generate**: Click "Generate" and wait for the result.
5. **History**: View and play past generations in the "History" tab.

## ğŸ“š Citation

If you use this code or model in your research, please cite:

```bibtex
@article{zhou2025indextts2,
  title={IndexTTS2: A Breakthrough in Emotionally Expressive and Duration-Controlled Auto-Regressive Zero-Shot Text-to-Speech},
  author={Siyi Zhou, Yiquan Zhou, Yi He, Xun Zhou, Jinchao Wang, Wei Deng, Jingchen Shu},
  journal={arXiv preprint arXiv:2506.21619},
  year={2025}
}
```

---

<div id="ä¸­æ–‡è¯´æ˜"></div>

<div align="center">
  <h1>IndexTTS 2-Multi-launcher</h1>
</div>

## ğŸ“– ç®€ä»‹

**IndexTTS 2-Multi-launcher** æ˜¯ä¸€ä¸ªåœ¨**æƒ…æ„Ÿè¡¨è¾¾**å’Œ**æ—¶é•¿æ§åˆ¶**æ–¹é¢å–å¾—çªç ´çš„è‡ªå›å½’é›¶æ ·æœ¬è¯­éŸ³åˆæˆç³»ç»Ÿã€‚

ä¸ä¼ ç»Ÿçš„ TTS æ¨¡å‹ä¸åŒï¼ŒIndexTTS 2-Multi-launcher å…è®¸æ‚¨ï¼š

- **æƒ…æ„Ÿæ§åˆ¶**ï¼šé€šè¿‡æ–‡æœ¬æç¤ºæˆ–å‚è€ƒéŸ³é¢‘ç”Ÿæˆå…·æœ‰ä¸°å¯Œã€ç‰¹å®šæƒ…æ„Ÿï¼ˆå¦‚å¼€å¿ƒã€æ„¤æ€’ã€æ‚²ä¼¤ç­‰ï¼‰çš„è¯­éŸ³ã€‚
- **æ—¶é•¿æ§åˆ¶**ï¼šç²¾ç¡®æŒ‡å®šè¯­éŸ³ç‰‡æ®µçš„æ—¶é•¿ï¼Œå®Œç¾é€‚é…è§†é¢‘é…éŸ³å¯¹å£å‹çš„éœ€æ±‚ã€‚
- **é›¶æ ·æœ¬å…‹éš†**ï¼šä»…éœ€ä¸€æ®µç®€çŸ­çš„å‚è€ƒéŸ³é¢‘ï¼ˆæ¨è 10-15 ç§’ï¼‰å³å¯å®ç°é«˜ä¿çœŸå£°éŸ³å…‹éš†ã€‚

æœ¬ä»“åº“åŒ…å«äº†å®˜æ–¹å®ç°ä»£ç ï¼Œå¹¶å†…ç½®äº†ä¸€ä¸ª**å›¾å½¢ç”¨æˆ·ç•Œé¢ (GUI)**ï¼Œæ–¹ä¾¿ç”¨æˆ·è¿›è¡Œæ¨ç†å’Œæ‰¹é‡å¤„ç†ã€‚

## âœ¨ ç‰¹æ€§

- **ğŸ­ ä¸°å¯Œçš„æƒ…æ„Ÿæ”¯æŒ**ï¼šæ”¯æŒä»æ–‡æœ¬è‡ªåŠ¨æ£€æµ‹æƒ…æ„Ÿï¼Œæˆ–é€šè¿‡å‘é‡æ‰‹åŠ¨æŒ‡å®šã€‚
- **â±ï¸ æ—¶é•¿æ§åˆ¶**ï¼šæ”¯æŒæŒ‡å®šç”Ÿæˆçš„è¯­éŸ³æ—¶é•¿ã€‚
- **ğŸ™ï¸ é›¶æ ·æœ¬å£°éŸ³å…‹éš†**ï¼šå•æ®µå‚è€ƒéŸ³é¢‘å³å¯å…‹éš†ã€‚
- **ğŸ–¥ï¸ å‹å¥½çš„ GUI ç•Œé¢**ï¼šåŸºäº Flet æ„å»ºçš„ç°ä»£åŒ–æš—è‰²ä¸»é¢˜ç•Œé¢ï¼Œæ”¯æŒï¼š
  - å®æ—¶æ—¥å¿—æŸ¥çœ‹ã€‚
  - ç”Ÿæˆå†å²ç®¡ç†ä¸å›æ”¾ã€‚
  - æ‰¹é‡ç”Ÿæˆç¼–è¾‘å™¨ã€‚
  - è‡ªåŠ¨æ›´æ–°åŠŸèƒ½ã€‚
- **ğŸš€ é«˜æ•ˆæ¨ç†**ï¼šé’ˆå¯¹ NVIDIA GPU ä¼˜åŒ–ï¼Œæ”¯æŒ BigVGAN CUDA ç®—å­åŠ é€Ÿã€‚

## ğŸ› ï¸ å®‰è£…æŒ‡å—

### å‰ç½®è¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Windows 10/11 (æ¨è) æˆ– Linuxã€‚
- **Python**: æ¨èä½¿ç”¨ Python 3.10ã€‚
- **GPU**: NVIDIA æ˜¾å¡ï¼Œå»ºè®®å®‰è£… CUDA 11.8+ ä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚

### å®‰è£…æ­¥éª¤

1. **å…‹éš†ä»“åº“**

   ```bash
   git clone https://github.com/qformat/indextts2-Multi-launcher.git
   cd indextts2-Multi-launcher
   ```

2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**

   ```bash
   python -m venv venv
   # æ¿€æ´»ç¯å¢ƒ:
   # Windows:
   .\venv\Scripts\activate
   # Linux:
   source venv/bin/activate
   ```

3. **å®‰è£…ä¾èµ–**

   ```bash
   # é¦–å…ˆå®‰è£…å¸¦ CUDA æ”¯æŒçš„ PyTorch (æ ¹æ®æ‚¨çš„ CUDA ç‰ˆæœ¬è°ƒæ•´)
   pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118

   # å®‰è£…å…¶ä»–ä¾èµ–
   pip install -r requirements.txt
   ```

## ğŸ“¥ æ¨¡å‹ä¸‹è½½ä¸è®¾ç½®

IndexTTS 2-Multi-launcher éœ€è¦å¤šä¸ªæ¨¡å‹æ–‡ä»¶æ‰èƒ½è¿è¡Œã€‚éƒ¨åˆ†æ¨¡å‹å¯ä»¥è‡ªåŠ¨ä¸‹è½½ï¼Œä½†**æ ¸å¿ƒæ¨¡å‹å¿…é¡»æ‰‹åŠ¨ä¸‹è½½**ã€‚

### 1. æ ¸å¿ƒæ¨¡å‹ (å¿…é¡»æ‰‹åŠ¨ä¸‹è½½)

è¯·ä» [HuggingFace](https://huggingface.co/IndexTeam/IndexTTS-2.0) æˆ– [ModelScope (é­”æ­)](https://modelscope.cn/models/IndexTeam/IndexTTS-2.0) ä¸‹è½½ä»¥ä¸‹æ–‡ä»¶ï¼Œå¹¶æ”¾å…¥ `checkpoints/` ç›®å½•ï¼š

| æ–‡ä»¶å      | è¯´æ˜           | ç›®æ ‡è·¯å¾„                |
| :---------- | :------------- | :---------------------- |
| `gpt.pth`   | GPT ä¸»æ¨¡å‹æƒé‡ | `checkpoints/gpt.pth`   |
| `s2mel.pth` | æ‰©æ•£æ¨¡å‹æƒé‡   | `checkpoints/s2mel.pth` |
| `feat1.pt`  | è¯´è¯äººç‰¹å¾çŸ©é˜µ | `checkpoints/feat1.pt`  |
| `feat2.pt`  | æƒ…æ„Ÿç‰¹å¾çŸ©é˜µ   | `checkpoints/feat2.pt`  |

### 2. è¾…åŠ©æ¨¡å‹ (è‡ªåŠ¨/æ‰‹åŠ¨)

è¿™äº›æ¨¡å‹ç”±ç¬¬ä¸‰æ–¹åº“ï¼ˆTransformers, BigVGANï¼‰ç®¡ç†ã€‚å¦‚æœç¼ºå¤±ï¼Œç¨‹åºä¼šå°è¯•è‡ªåŠ¨ä¸‹è½½ã€‚**å¦‚æœæ‚¨çš„ç½‘ç»œè¿æ¥ HuggingFace æœ‰å›°éš¾**ï¼Œè¯·æ‰‹åŠ¨ä¸‹è½½å¹¶æŒ‰å¦‚ä¸‹è·¯å¾„æ”¾ç½®ï¼š

| æ¨¡å‹åç§°         | åŸå§‹æ¥æº                              | æ¨èæ‰‹åŠ¨æ”¾ç½®è·¯å¾„                                               |
| :--------------- | :------------------------------------ | :------------------------------------------------------------- |
| **Qwen Emotion** | `Qwen/Qwen1.5-0.5B-Chat`              | `checkpoints/hub/qwen0.6bemo4-merge` (è§£å‹è‡³æ­¤)                |
| **BigVGAN**      | `nvidia/bigvgan_v2_22khz_80band_256x` | `checkpoints/nvidia_bigvgan_v2_22khz_80band_256x`              |
| **W2V-BERT**     | `facebook/w2v-bert-2.0`               | `checkpoints/hub/models--facebook--w2v-bert-2.0` (HF ç¼“å­˜æ ¼å¼) |
| **MaskGCT**      | `amphion/MaskGCT`                     | `checkpoints/amphion_MaskGCT/semantic_codec/model.safetensors` |

> **æ³¨æ„**: Qwen æƒ…æ„Ÿæ¨¡å‹åœ¨é…ç½®æ–‡ä»¶ä¸­é»˜è®¤æŒ‡å‘ `checkpoints/hub/qwen0.6bemo4-merge`ï¼Œæ‰‹åŠ¨ä¸‹è½½åè¯·ç¡®ä¿æ–‡ä»¶å¤¹åç§°ä¸€è‡´ã€‚

### ğŸŒ æ— æ³•è®¿é—® HuggingFaceï¼Ÿä½¿ç”¨é•œåƒç«™

å¦‚æœæ‚¨æ— æ³•è¿æ¥ Hugging Faceï¼Œå¯ä»¥ä½¿ç”¨å›½å†…é•œåƒç«™ã€‚åœ¨è¿è¡Œç¨‹åºå‰è®¾ç½®ç¯å¢ƒå˜é‡ï¼š

**PowerShell (Windows):**

```powershell
$env:HF_ENDPOINT = "https://hf-mirror.com"
python launcher.py
```

**Bash (Linux):**

```bash
export HF_ENDPOINT=https://hf-mirror.com
python src/main.py
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### å¯åŠ¨ GUI

è¿è¡Œå¯åŠ¨è„šæœ¬æ‰“å¼€ç¨‹åºï¼š

```bash
python launcher.py
```

### åŸºæœ¬æ“ä½œ

1. **é€‰æ‹©æ¨¡å‹**ï¼šåœ¨è®¾ç½®é¡µç¡®è®¤æ¨¡å‹è·¯å¾„æ­£ç¡®ã€‚
2. **å‚è€ƒéŸ³é¢‘**ï¼šä¸Šä¼ ä¸€æ®µæ¸…æ™°çš„è¯­éŸ³ï¼ˆ10-15 ç§’ï¼‰ä½œä¸ºå…‹éš†å¯¹è±¡ã€‚
3. **è¾“å…¥æ–‡æœ¬**ï¼šè¾“å…¥æ‚¨æƒ³è¦åˆæˆçš„æ–‡å­—ã€‚
4. **ç”Ÿæˆ**ï¼šç‚¹å‡»â€œç”Ÿæˆâ€æŒ‰é’®ï¼Œç­‰å¾…ç‰‡åˆ»ã€‚
5. **å†å²è®°å½•**ï¼šåœ¨â€œç”Ÿæˆè®°å½•â€é¡µé¢æŸ¥çœ‹å’Œæ’­æ”¾ç”Ÿæˆçš„éŸ³é¢‘ã€‚

## ğŸ“š å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†æœ¬ä»£ç æˆ–æ¨¡å‹ï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š

```bibtex
@article{zhou2025indextts2,
  title={IndexTTS2: A Breakthrough in Emotionally Expressive and Duration-Controlled Auto-Regressive Zero-Shot Text-to-Speech},
  author={Siyi Zhou, Yiquan Zhou, Yi He, Xun Zhou, Jinchao Wang, Wei Deng, Jingchen Shu},
  journal={arXiv preprint arXiv:2506.21619},
  year={2025}
}
```
